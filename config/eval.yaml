# Evaluation configuration template for EzSpeech models
# Copy this file and update paths for your specific evaluation setup

# Model checkpoint to evaluate (REQUIRED - update this path)
model_checkpoint: /path/to/your/model.ckpt

# Evaluation settings
eval_batch_size: 8
eval_num_workers: 4
output_dir: outputs/evaluation

# Datasets to evaluate on (update these paths)
eval_datasets:
  test_set:
    _target_: ezspeech.modules.data.dataset.SpeechRecognitionDataset
    filepaths:
      - /path/to/test.jsonl
    data_dir: /path/to/audio/files

  validation_set:
    _target_: ezspeech.modules.data.dataset.SpeechRecognitionDataset
    filepaths:
      - /path/to/val.jsonl
    data_dir: /path/to/audio/files

# Individual files to evaluate (optional - update these paths)
eval_files:
  - audio_path: /path/to/sample1.wav
    reference_text: "hello world"
  - audio_path: /path/to/sample2.wav
    reference_text: "this is a test"

# Metrics configuration
metrics:
  # Basic metrics (always computed)
  basic: true

  # Detailed error analysis
  error_analysis: true

  # Confidence-based metrics (if model provides confidence scores)
  confidence_metrics: false

  # Text normalization for evaluation
  normalize_text: true

# Dataset configuration (inherited from training config)
dataset:
  spe_file_grapheme: /path/to/grapheme.model
  spe_file_phoneme: /path/to/phoneme.model

# Model configuration (subset needed for evaluation)
model:
  preprocessor:
    _target_: ezspeech.modules.data.utils.audio.AudioToMelSpectrogramPreprocessor
    sample_rate: 16000
    normalize: per_feature
    window_size: 0.025
    window_stride: 0.01
    window: hann
    features: 80
    n_fft: 512
    frame_splicing: 1
    dither: 1.0e-05
    pad_to: 0